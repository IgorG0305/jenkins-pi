# ===============================
# ğŸ“¦ ImportaÃ§Ã£o das DependÃªncias
# ===============================
# ... inÃ­cio do arquivo ...
import matplotlib
matplotlib.use('Agg')  # <- Adicione esta linha logo apÃ³s os imports do matplotlib
import matplotlib.pyplot as plt
# ... resto dos imports ...

# ... seu cÃ³digo ...

# Exemplo de alteraÃ§Ã£o para salvar grÃ¡ficos:
plt.figure(1, figsize=(12,6))
plt.title("Matriz de ConfusÃ£o - Modelo com 5 Aulas")
plt.savefig('/opt/spark/scripts/grafico1_matriz_confusao.png')
plt.close()

plt.figure(2, figsize=(10, 5))
# ... plot ...
plt.savefig('/opt/spark/scripts/grafico2_distribuicao_real_vs_predito.png')
plt.close()

# Repita para todos os grÃ¡ficos:
# plt.savefig('/opt/spark/scripts/graficoX_nome.png')
# plt.close()

# Exemplo para o trecho que vocÃª enviou:
plt.figure(8, figsize=(7,5))
colors = ['red', 'orange', 'green']
bars = plt.bar(df_contagem['classe_economica'], df_contagem['quantidade_evadidos'], color=colors)
for bar in bars:
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, height + 0.5, str(int(height)), ha='center')
plt.title('Quantidade de Alunos Evadidos por Classe EconÃ´mica')
plt.xlabel('Classe EconÃ´mica')
plt.ylabel('Quantidade')
plt.grid(axis='y', linestyle='--', alpha=0.5)
plt.tight_layout()
plt.savefig('/opt/spark/scripts/grafico8_evadidos_classe_economica.png')
plt.close()

# ... repita para os demais grÃ¡ficos ...

# No final do script, NÃƒO use plt.show() (ou deixe, mas nÃ£o farÃ¡ efeito em ambiente headless)
# ğŸ”¢ ManipulaÃ§Ã£o de Dados
import pandas as pd
import numpy as np
import time

# ğŸ“Š VisualizaÃ§Ã£o de Dados
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px

# ğŸ¤– Machine Learning - Scikit-learn
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestClassifier
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.linear_model import LinearRegression
from sklearn.metrics import (
    classification_report,
    ConfusionMatrixDisplay,
    silhouette_score,
    r2_score,
    mean_squared_error
)
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer

# ğŸ§  Aprendizado de MÃ¡quina - Balanceamento de Dados
from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline as ImbPipeline

# ğŸ“š Processamento de Linguagem Natural (PLN)
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords

# âš¡ Big Data com PySpark
from pyspark.sql import SparkSession
from pyspark.sql.functions import col
from pyspark.ml.feature import VectorAssembler, StringIndexer
from pyspark.ml.classification import DecisionTreeClassifier
from pyspark.ml.clustering import KMeans as SparkKMeans
from pyspark.ml.evaluation import MulticlassClassificationEvaluator

import matplotlib.pyplot as plt
import seaborn as sns

from sqlalchemy import create_engine
import pandas as pd

from pyspark.sql import SparkSession
from pyspark.sql.functions import col
from pyspark.ml.feature import StringIndexer, VectorAssembler
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
from sklearn.metrics import confusion_matrix

# ğŸ“¥ Carregar Base de Dados
#df = pd.read_csv(r"C:/Users/bruno/Downloads/PI_DATA_SCIENCE/Analise_BIGDATA_docker/ANALISE_PI/alunos_com_erros.csv")

# ğŸ“Š ExploraÃ§Ã£o Inicial
#print(df.head())
#print(df.info())
#print(df.isnull().sum())

# ================================
# ğŸ“Š VisualizaÃ§Ã£o Inicial com mysql

# ConfiguraÃ§Ã£o da conexÃ£o
usuario = 'dbpi'
senha = 'walker1207'
host = 'db'
porta = 3306
nome_banco = 'faculdades1'

# String de conexÃ£o
engine = create_engine(f'mysql+pymysql://{usuario}:{senha}@{host}:{porta}/{nome_banco}')


# Consulta os dados da tabela alunos
query = "SELECT * FROM alunos_tratados"

df = pd.read_sql(query, con=engine)

# Conferir os dados
print(df.head())
print(df.info())
print(df.isnull().sum())
# Verificar os tipos de dados
print(df.dtypes)
# Verificar os valores Ãºnicos de cada coluna
for col in df.columns:
    print(f"Valores Ãºnicos em {col}: {df[col].unique()}")
    

# =================================

# ===============================
# ğŸ“Œ PrÃ©-processamento (Pandas)
# ===============================

# Remover registros com valores nulos e criar cÃ³pia
df_model = df.dropna().copy()

# Label Encoding para colunas categÃ³ricas (exceto target)
label_encoders = {}
for c in df_model.select_dtypes(include='object').columns:
    if c != 'risco_evasao':
        le = LabelEncoder()
        df_model.loc[:, c] = le.fit_transform(df_model[c].astype(str))
        label_encoders[c] = le

# Separar features e target
X = df_model.drop(columns=['risco_evasao'])
y = df_model['risco_evasao']

# Codificar target
le_y = LabelEncoder()
y_encoded = le_y.fit_transform(y)

# Normalizar features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# ===============================
# ğŸ“Š Modelo de ClassificaÃ§Ã£o (Random Forest)
# ===============================

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)

clf = RandomForestClassifier(n_estimators=100, random_state=42)
clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

print("RelatÃ³rio de ClassificaÃ§Ã£o:")
print(classification_report(y_test, y_pred, target_names=le_y.classes_.astype(str)))

# ===============================
# ğŸ“‰ RegressÃ£o Linear
# ===============================
from sklearn.linear_model import Ridge
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.pipeline import Pipeline
import pandas as pd
from sqlalchemy import create_engine

# Conectar ao banco e carregar dados no pandas
engine = create_engine("mysql+pymysql://root:@localhost:3306/faculdade")
df_model = pd.read_sql("SELECT * FROM alunos_tratados", con=engine)

if 'desempenho_1' in df_model.columns:
    X_reg = df_model.drop(columns=['desempenho_1'], errors='ignore')
    y_reg = df_model['desempenho_1']

    # Remover colunas de alta cardinalidade
    high_card_cols = ['nome_aluno', 'email', 'professor_1', 'professor_2', 'professor_3', 'professor_4', 'professor_5']
    X_reg = X_reg.drop(columns=high_card_cols, errors='ignore')

    # Transformar variÃ¡veis categÃ³ricas em numÃ©ricas
    X_reg_encoded = pd.get_dummies(X_reg, drop_first=True)

    # Codificar target
    le = LabelEncoder()
    y_encoded = le.fit_transform(y_reg.astype(str))

    # Dividir dados
    X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(
        X_reg_encoded, y_encoded, test_size=0.2, random_state=42
    )

    # Pipeline com Ridge Regression (mais rÃ¡pido)
    pipeline = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='mean')),
        ('scaler', StandardScaler()),
        ('regressor', Ridge())
    ])

    # Treinar pipeline
    pipeline.fit(X_train_r, y_train_r)

    # Fazer prediÃ§Ãµes
    y_pred_r = pipeline.predict(X_test_r)

    # Avaliar o modelo
    print("RÂ²:", r2_score(y_test_r, y_pred_r))
    print("MSE:", mean_squared_error(y_test_r, y_pred_r))
    print("Formato final das features:", X_reg_encoded.shape)

    print("Classes desempenho_1 codificadas:", list(le.classes_))
else:
    print("Coluna desempenho_1 nÃ£o encontrada na tabela.")
# ===============================
# fim RegressÃ£o Linear
# ===============================

# ===============================
# ğŸ“ˆ ClusterizaÃ§Ã£o (KMeans + PCA)
# ===============================

# ClusterizaÃ§Ã£o
kmeans = KMeans(n_clusters=3, random_state=42)
clusters = kmeans.fit_predict(X_scaled)

print("Silhouette Score:", silhouette_score(X_scaled, clusters))

# PCA para 2D
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

df_plot = pd.DataFrame({
    'PCA1': X_pca[:, 0],
    'PCA2': X_pca[:, 1],
    'Cluster': clusters
})

# GrÃ¡fico interativo
fig = px.scatter(
    df_plot, x='PCA1', y='PCA2',
    color=df_plot['Cluster'].astype(str),
    title='Clusters dos Alunos (KMeans + PCA)',
    color_discrete_sequence=px.colors.qualitative.Set2
)

fig.update_traces(marker=dict(size=10, line=dict(width=1, color='DarkSlateGrey')))
fig.show()

# âœ… VariÃ¡veis Ãºteis: agora com dados das 5 aulas
features = [
    'sexo', 'idade', 'trabalha', 'renda_familiar', 'acompanhamento_medico',
    'tem_filho', 'estado_civil', 'curso', 'status', 'turma',
    'semestre', 'bimestre',
    # Aulas 1 a 5
    'aula_1', 'professor_1', 'notas_1', 'faltas_1',
    'aula_2', 'professor_2', 'notas_2', 'faltas_2',
    'aula_3', 'professor_3', 'notas_3', 'faltas_3',
    'aula_4', 'professor_4', 'notas_4', 'faltas_4',
    'aula_5', 'professor_5', 'notas_5', 'faltas_5'
]
target = 'desempenho_1'  # ou mude para 'risco_evasao' ou 'desempenho_final', se desejar

# ğŸ” Eliminar registros com target ausente
df_valid = df.dropna(subset=[target])
X = df_valid[features]
y = df_valid[target]

# âš™ï¸ Identificar tipos de variÃ¡veis
cat_cols = X.select_dtypes(include='object').columns.tolist()
num_cols = X.select_dtypes(include=['int64', 'float64', 'bool']).columns.tolist()

# ğŸ”§ Pipelines de transformaÃ§Ã£o
cat_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('encoder', OneHotEncoder(handle_unknown='ignore'))
])
num_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

preprocessor = ColumnTransformer([
    ('cat', cat_pipeline, cat_cols),
    ('num', num_pipeline, num_cols)
])

# ğŸ§ª Dividir treino/teste com estratificaÃ§Ã£o
X_train, X_test, y_train, y_test = train_test_split(
    X, y, stratify=y, test_size=0.2, random_state=42
)

# ğŸ¤– Pipeline com SMOTE e Random Forest
model = ImbPipeline(steps=[
    ('preprocessing', preprocessor),
    ('oversample', SMOTE(random_state=42)),
    ('classifier', RandomForestClassifier(class_weight='balanced', random_state=42))
])

# ğŸ“ˆ Treinar e Avaliar
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

from pyspark.sql import SparkSession
from pyspark.sql.functions import col
from pyspark.ml.feature import StringIndexer, VectorAssembler
from pyspark.ml.classification import RandomForestClassifier
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
from sklearn.metrics import confusion_matrix

# ===============================
# ğŸ”§ Iniciar sessÃ£o Spark (com Hadoop se quiser)
# ===============================

spark = SparkSession.builder \
    .appName("PrevisaoRiscoEvasao") \
    .config("spark.hadoop.fs.defaultFS", "hdfs://localhost:9000") \
    .config("spark.jars", "file:///C:/pyspark_drivers/mysql-connector-j-9.3.0/mysql-connector-j-9.3.0.jar") \
    .getOrCreate()

# ===============================
# ğŸ“¥ Leitura dos dados via JDBC
# ===============================
df_spark = spark.read.format("jdbc").options(
    url="jdbc:mysql://db:3306/faculdades1", # <--- CORRETO!
    driver="com.mysql.cj.jdbc.Driver",
    dbtable="alunos_tratados",
    user="dbpi",
    password="walker1207"
).load()

df_spark.printSchema()
df_spark.show(5)

# ===============================
# ğŸ§¼ Limpeza e conversÃ£o
# ===============================
colunas_numericas = ["idade", "renda_familiar", "faltas_1", "notas_1", "faltas_2", "notas_2",
                     "faltas_3", "notas_3", "faltas_4", "notas_4", "faltas_5", "notas_5"]
colunas_categoricas = ["sexo", "trabalha", "acompanhamento_medico", "tem_filho",
                       "estado_civil", "desempenho_1", "desempenho_2",
                       "desempenho_3", "desempenho_4", "desempenho_5", "risco_evasao"]

for coln in colunas_numericas:
    df_spark = df_spark.withColumn(coln, col(coln).cast("double"))
    df_spark = df_spark.na.fill({coln: -1})

for colc in colunas_categoricas:
    df_spark = df_spark.na.fill({colc: "desconhecido"})
    indexer = StringIndexer(inputCol=colc, outputCol=colc + "_idx", handleInvalid="keep")
    df_spark = indexer.fit(df_spark).transform(df_spark)

# ===============================
# ğŸ”„ VetorizaÃ§Ã£o
# ===============================
feature_cols = colunas_numericas + [col + "_idx" for col in colunas_categoricas[:-1]]
assembler = VectorAssembler(inputCols=feature_cols, outputCol="features_vec")
df_spark = assembler.transform(df_spark)

# ===============================
# ğŸŒ³ Random Forest Classifier
# ===============================
rf = RandomForestClassifier(labelCol="risco_evasao_idx", featuresCol="features_vec")
model = rf.fit(df_spark)
predictions = model.transform(df_spark)

# ===============================
# ğŸ“Š AvaliaÃ§Ã£o
# ===============================
evaluator = MulticlassClassificationEvaluator(
    labelCol="risco_evasao_idx", predictionCol="prediction", metricName="accuracy"
)
accuracy = evaluator.evaluate(predictions)
print(f"AcurÃ¡cia do modelo: {accuracy:.4f}")

# ===============================
# ğŸ“ˆ VisualizaÃ§Ãµes
# ===============================
# Coleta os dados manualmente
data = predictions.select("risco_evasao_idx", "prediction").collect()

# Converte para pandas
preds_pd = pd.DataFrame(data, columns=["risco_evasao_idx", "prediction"])

# ===============================
# ğŸ“„ InformaÃ§Ãµes adicionais
# ===============================
# print("\nInformaÃ§Ãµes do DataFrame Spark:")
# print("Colunas disponÃ­veis:", df_spark.columns)
# print("Contagem de linhas:", df_spark.count())

# print("Contagem de valores nulos por coluna:")
# df_spark.select([col(c).isNull().cast("int").alias(c) for c in df_spark.columns]) \
#     .agg(*[sum(col(c)).alias(c) for c in df_spark.columns]).show()

# print("DistribuiÃ§Ã£o de classes (risco_evasao):")
# df_spark.groupBy("risco_evasao").count().show()

# print("DistribuiÃ§Ã£o de classes (risco_evasao_idx):")
# df_spark.groupBy("risco_evasao_idx").count().show()
# ===============================
# ğŸ“ˆ VisualizaÃ§Ãµes com Pandas, Seaborn e Matplotlib
# ===============================
# Coleta os dados manualmente
data = predictions.select("risco_evasao_idx", "prediction").collect()

# Converte para pandas
preds_pd = pd.DataFrame(data, columns=["risco_evasao_idx", "prediction"])

# ===============================
# ğŸ“Š Converter para Pandas e gerar grÃ¡fico
# ===============================

# Converter para Pandas
data = df_spark.collect()
df_pandas = pd.DataFrame([row.asDict() for row in data])

# Tratar valores nulos
df_pandas['risco_evasao'] = df_pandas['risco_evasao'].fillna('Desconhecido')

# ===============================
# ğŸ“‹ PrevisÃµes Spark para anÃ¡lise detalhada
# ===============================

# Mapear as classes numÃ©ricas para texto (exemplo)
map_labels = {0: "Baixo", 1: "MÃ©dio", 2: "Alto"}

# Converter previsÃµes Spark para Pandas
predictions_pandas = predictions.select("aluno_id", "prediction").toPandas()
predictions_pandas['risco_predito'] = predictions_pandas['prediction'].map(map_labels)

# Ajustar tipos para merge
df_model['aluno_id'] = df_model['aluno_id'].astype(str)
predictions_pandas['aluno_id'] = predictions_pandas['aluno_id'].astype(str)

# Remover coluna risco_predito anterior para evitar conflito
if 'risco_predito' in df_model.columns:
    df_model = df_model.drop(columns=['risco_predito'])

# Merge das previsÃµes Spark no df_model
df_model = df_model.merge(predictions_pandas[['aluno_id', 'risco_predito']], on='aluno_id', how='inner')

print("Colunas apÃ³s merge:", df_model.columns)
print(df_model.head())

# Filtrar alunos de alto risco
alunos_alto_risco = df_model[df_model['risco_predito'] == 'Alto']
print(alunos_alto_risco[['nome_aluno', 'desempenho_1', 'faltas_1', 'notas_1']].head())

# GrÃ¡fico percentual dos riscos preditos
# Calcular os percentuais
risco_counts = df_model['risco_predito'].value_counts(normalize=True) * 100

# Converter para DataFrame para plotar
df_risco_counts = risco_counts.reset_index()
df_risco_counts.columns = ['risco_predito', 'percentual']

# GrÃ¡fico interativo
fig = px.bar(
    df_risco_counts,
    x='risco_predito',
    y='percentual',
    color='risco_predito',
    text='percentual',
    color_discrete_sequence=px.colors.qualitative.Set1,
    title='DistribuiÃ§Ã£o percentual dos riscos preditos'
)

fig.update_layout(
    yaxis_title="Porcentagem (%)",
    xaxis_title="Risco Predito",
    showlegend=False
)

fig.update_traces(texttemplate='%{text:.2f}%', textposition='outside')

fig.show()

# VariÃ¡veis (features) que vai usar para treinar (sem identificadores e target)
features_all = [
    "curso", "status", "turma", "sexo", "idade", "trabalha", "renda_familiar", "acompanhamento_medico",
    "tem_filho", "estado_civil", "semestre", "bimestre",
    "aula_1", "professor_1", "notas_1", "faltas_1", "desempenho_1",
    "aula_2", "professor_2", "notas_2", "faltas_2", "desempenho_2",
    "aula_3", "professor_3", "notas_3", "faltas_3", "desempenho_3",
    "aula_4", "professor_4", "notas_4", "faltas_4", "desempenho_4",
    "aula_5", "professor_5", "notas_5", "faltas_5", "desempenho_5"
]

# Preprocessar seu dataframe (exemplo rÃ¡pido, ajuste conforme seu caso):
X = df_model[features_all].copy()
y = df_model['risco_evasao']

# Se tem variÃ¡veis categÃ³ricas, transforme em numÃ©rico (LabelEncoder ou get_dummies)
X_encoded = pd.get_dummies(X, drop_first=True)  # codifica as categorias

# Treina modelo RandomForest
assembler = VectorAssembler(inputCols=feature_cols, outputCol="features")
df_spark = assembler.transform(df_spark)

rf = RandomForestClassifier(labelCol="risco_evasao_idx", featuresCol="features", numTrees=100)
model = rf.fit(df_spark)

# Extrai importÃ¢ncia das features
importances = model.featureImportances.toArray()

# Nomes das features apÃ³s o get_dummies
feature_names = assembler.getInputCols()

# 4. Organizar para visualizaÃ§Ã£o
df_imp = pd.DataFrame({
    'VariÃ¡vel': feature_names,
    'ImportÃ¢ncia': importances
}).sort_values(by='ImportÃ¢ncia', ascending=False)

# 5. GrÃ¡fico interativo
fig = px.bar(
    df_imp.head(10),
    x='ImportÃ¢ncia',
    y='VariÃ¡vel',
    orientation='h',
    color='ImportÃ¢ncia',
    color_continuous_scale='Viridis',
    title='ImportÃ¢ncia das VariÃ¡veis para PrediÃ§Ã£o do Risco de EvasÃ£o (PySpark)',
    labels={'ImportÃ¢ncia': 'ImportÃ¢ncia da Feature', 'VariÃ¡vel': 'Feature'}
)
fig.update_layout(yaxis=dict(categoryorder='total ascending'))
fig.show()

# Copiar e preparar dados, garantir que coluna de evasÃ£o estÃ¡ presente e limpa
df_plot = df.copy().dropna(subset=['renda_familiar', 'risco_evasao'])

# Converter para numÃ©rico, forÃ§ando erros para NaN
df_plot['renda_familiar'] = pd.to_numeric(df_plot['renda_familiar'], errors='coerce')

# Remover valores nulos resultantes da conversÃ£o
df_plot = df_plot.dropna(subset=['renda_familiar'])

# Criar categorias econÃ´micas baseadas na renda familiar
df_plot['classe_economica'] = pd.cut(
    df_plot['renda_familiar'],
    bins=[-np.inf, 4000, 8000, np.inf],
    labels=['Baixa', 'MÃ©dia', 'Alta']
)

# Assumindo que 'risco_evasao' Ã© 1 para evadiu e 0 para nÃ£o evadiu
# Filtrar apenas alunos que evadiram
df_evadidos = df_plot[df_plot['risco_evasao'] == 1]

# Contar nÃºmero de evadidos por classe econÃ´mica
df_contagem = df_evadidos.groupby('classe_economica').size().reset_index(name='quantidade_evadidos')

# Se quiser mostrar barras mesmo para classes sem evadidos, garantimos todas as categorias
todas_classes = ['Baixa', 'MÃ©dia', 'Alta']
df_contagem = df_contagem.set_index('classe_economica').reindex(todas_classes, fill_value=0).reset_index()

# GrÃ¡fico interativo
fig = px.bar(
    df_contagem,
    x='classe_economica',
    y='quantidade_evadidos',
    labels={'classe_economica': 'Classe EconÃ´mica', 'quantidade_evadidos': 'Quantidade de Alunos Evadidos'},
    title='Quantidade de Alunos Evadidos por Classe EconÃ´mica (Renda Familiar)',
    color='classe_economica',
    color_discrete_map={'Baixa': 'red', 'MÃ©dia': 'orange', 'Alta': 'green'},
    width=700,
    height=500
)

fig.update_layout(
    yaxis=dict(title='Quantidade de Alunos Evadidos', dtick=1),
    xaxis=dict(title='Classe EconÃ´mica'),
    showlegend=False,
    hoverlabel=dict(bgcolor="white", font_size=12, font_family="Arial")
)

fig.show()

# Preparar dados: filtrar faltas e evasÃ£o
df_faltas = df.copy().dropna(subset=['faltas_1', 'risco_evasao'])

# Filtrar apenas alunos que evadiram
df_evadidos = df_faltas[df_faltas['risco_evasao'] == 1]

# Contar evadidos por nÃºmero de faltas
df_faltas_count = df_evadidos.groupby('faltas_1').size().reset_index(name='quantidade_evadidos')

# Ordenar por nÃºmero de faltas para visualizaÃ§Ã£o mais clara
df_faltas_count = df_faltas_count.sort_values(by='faltas_1')

# GrÃ¡fico interativo
fig = px.bar(
    df_faltas_count,
    x='faltas_1',
    y='quantidade_evadidos',
    labels={'faltas_1': 'NÃºmero de Faltas', 'quantidade_evadidos': 'Quantidade de Alunos Evadidos'},
    title='Quantidade de Alunos Evadidos por NÃºmero de Faltas',
    width=800,
    height=500
)

fig.update_layout(
    xaxis=dict(dtick=1),  # mostrar cada nÃºmero de falta no eixo x
    yaxis=dict(dtick=1),
    hoverlabel=dict(bgcolor="white", font_size=12, font_family="Arial")
)

fig.show()

# 1. Preparar os dados
df_evasao = df.copy().dropna(subset=['semestre', 'risco_evasao'])

# Filtrar apenas alunos com risco de evasÃ£o
df_evasao = df_evasao[df_evasao['risco_evasao'] == 1]

# 2. Contar evasÃµes por semestre
evasao_por_semestre = df_evasao['semestre'].value_counts().reset_index()
evasao_por_semestre.columns = ['semestre', 'total_evasoes']

# 3. Calcular porcentagem do total
total_alunos_por_semestre = df['semestre'].value_counts().reset_index()
total_alunos_por_semestre.columns = ['semestre', 'total_alunos']

dados_plot = evasao_por_semestre.merge(total_alunos_por_semestre, on='semestre')
dados_plot['percentual_evasao'] = (dados_plot['total_evasoes'] / dados_plot['total_alunos'] * 100).round(1)

# 4. Criar grÃ¡fico interativo
fig = px.bar(
    dados_plot,
    x='semestre',
    y=['total_evasoes', 'percentual_evasao'],
    barmode='group',
    title='DistribuiÃ§Ã£o de EvasÃ£o por Semestre',
    labels={
        'semestre': 'Semestre',
        'value': 'Contagem/Percentual',
        'variable': 'MÃ©trica'
    },
    color_discrete_sequence=['#e74c3c', '#3498db'],
    text_auto=True,
    width=900,
    height=500
)

# 5. Personalizar layout
fig.update_layout(
    xaxis=dict(
        title='Semestre',
        type='category',
        tickmode='linear'
    ),
    yaxis_title="Valor",
    legend_title="MÃ©trica",
    hovermode="x unified",
    hoverlabel=dict(
        bgcolor="white",
        font_size=12,
        font_family="Arial"
    )
)

# 6. Renomear legendas
fig.for_each_trace(lambda t: t.update(name='Total de EvasÃµes' if t.name == 'total_evasoes' else 'Percentual de EvasÃ£o (%)'))

# 7. Adicionar informaÃ§Ãµes complementares
fig.update_traces(
    textposition='outside',
    hovertemplate=(
        "<b>Semestre %{x}</b><br><br>" +
        "Total de evasÃµes: %{y}<br>" +
        "Percentual: %{customdata[0]}%<extra></extra>"
    ),
    customdata=dados_plot[['percentual_evasao']]
)

fig.show()

# ===============================
# ğŸ“Š PCA + RandomForest: VisualizaÃ§Ã£o interativa
# ===============================

# GrÃ¡fico interativo
df_pca = pd.DataFrame(X_pca, columns=['PC1', 'PC2'])
df_pca['Cluster'] = clusters
df_pca['Risco_Predito'] = df_model['risco_predito']

fig = px.scatter(
    df_pca, x='PC1', y='PC2', color='Risco_Predito',
    title='Alunos por Risco de EvasÃ£o (PCA + RandomForest)',
    labels={'PC1':'Componente Principal 1', 'PC2':'Componente Principal 2'}
)
fig.show()

# --- Exemplo: definir motivo de evasÃ£o com base em regras simples ---
# ForÃ§ar para numÃ©rico (transforma erros em NaN)
df_model['faltas_1'] = pd.to_numeric(df_model['faltas_1'], errors='coerce')
df_model['desempenho_1'] = pd.to_numeric(df_model['desempenho_1'], errors='coerce')
df_model['renda_familiar'] = pd.to_numeric(df_model['renda_familiar'], errors='coerce')

# Remover linhas com NaN em alguma dessas colunas
df_model = df_model.dropna(subset=['faltas_1', 'desempenho_1', 'renda_familiar'])

# Se tiver a coluna 'motivo_evasao' use ela, senÃ£o a gente simula baseada nas variÃ¡veis
def definir_motivo(row):
    if row['faltas_1'] > 10:
        return 'Faltas Excessivas'
    elif row['desempenho_1'] < 5:
        return 'Baixo Desempenho'
    elif row['renda_familiar'] < 1500:
        return 'Baixa Renda'
    else:
        return 'Outro'

# Criar coluna de motivo (caso nÃ£o exista)
if 'motivo_evasao' not in df_model.columns:
    df_model['motivo_evasao'] = df_model.apply(definir_motivo, axis=1)

# --- Contagem dos motivos por risco predito ---
df_motivos = df_model.groupby(['risco_predito', 'motivo_evasao']).size().reset_index(name='quantidade')

# --- GrÃ¡fico interativo com Plotly ---
fig = px.bar(
    df_motivos,
    x='motivo_evasao',
    y='quantidade',
    color='risco_predito',
    barmode='group',
    text='quantidade',
    title='DistribuiÃ§Ã£o dos Motivos de EvasÃ£o por Categoria de Risco',
    labels={'motivo_evasao': 'Motivo de EvasÃ£o', 'quantidade': 'NÃºmero de Alunos'}
)

fig.update_layout(
    xaxis_title='Motivo de EvasÃ£o',
    yaxis_title='NÃºmero de Alunos',
    legend_title='Risco Predito',
    bargap=0.3
)

fig.show()


#Graficos EstÃ¡ticos

# GrÃ¡fico 1: RelatÃ³rio Final (5 aulas)
print("ğŸ“‹ RelatÃ³rio Final (5 Aulas):")
print(classification_report(y_test, y_pred))
ConfusionMatrixDisplay.from_predictions(y_test, y_pred)
plt.figure(1, figsize=(12,6))
plt.title("Matriz de ConfusÃ£o - Modelo com 5 Aulas")

# GrÃ¡fico 2: DistribuiÃ§Ã£o Real vs Predito
plt.figure(2, figsize=(10, 5))
sns.countplot(data=preds_pd, x="risco_evasao_idx", color="blue", label="Real", alpha=0.6)
sns.countplot(data=preds_pd, x="prediction", color="red", label="Predito", alpha=0.6)
plt.title("DistribuiÃ§Ã£o das Classes - Real vs Predita")
plt.xlabel("Classe (risco_evasao)")
plt.ylabel("Contagem")
plt.legend()
plt.grid(True)

# GrÃ¡fico 3: Matriz de ConfusÃ£o
conf_mat = confusion_matrix(preds_pd["risco_evasao_idx"], preds_pd["prediction"])
plt.figure(3, figsize=(8, 6))
sns.heatmap(conf_mat, annot=True, fmt="d", cmap="Blues")
plt.title("Matriz de ConfusÃ£o")
plt.xlabel("Predito")
plt.ylabel("Real")

# GrÃ¡fico 4: AcurÃ¡cia do Modelo 
labels = ['AcurÃ¡cia', 'Erro']
sizes = [accuracy, 1 - accuracy]
plt.figure(4, figsize=(6, 6))
plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90, colors=['#4CAF50', '#F44336'])
plt.title('AcurÃ¡cia do Modelo de EvasÃ£o')

# GrÃ¡fico 5: Top 5 cursos com mais risco de evasÃ£o
plt.figure(5, figsize=(8,5))
bars = plt.bar(df_risco_counts['risco_predito'], df_risco_counts['percentual'], color='skyblue')

for bar in bars:
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, height + 1, f'{height:.2f}%', ha='center')

plt.title('DistribuiÃ§Ã£o percentual dos riscos preditos')
plt.xlabel('Risco Predito')
plt.ylabel('Percentual (%)')
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()

# GrÃ¡fico 6: Top 10 VariÃ¡veis para PrediÃ§Ã£o do Risco de EvasÃ£o
top_imp = df_imp.head(10)

plt.figure(6, figsize=(8,6))
plt.barh(top_imp['VariÃ¡vel'], top_imp['ImportÃ¢ncia'], color='mediumseagreen')
plt.xlabel('ImportÃ¢ncia')
plt.title('Top 10 VariÃ¡veis para PrediÃ§Ã£o do Risco de EvasÃ£o')
plt.gca().invert_yaxis()
plt.grid(axis='x', linestyle='--', alpha=0.7)
plt.tight_layout()

# GrÃ¡fico 7: Alunos por Risco de EvasÃ£o (PCA + RandomForest)
import seaborn as sns

plt.figure(7, figsize=(8,6))
sns.scatterplot(data=df_pca, x='PC1', y='PC2', hue='Risco_Predito', palette='Set2', s=100, edgecolor='black')
plt.title('Alunos por Risco de EvasÃ£o (PCA + RandomForest)')
plt.grid(True, linestyle='--', alpha=0.6)
plt.tight_layout()

# GrÃ¡fico 8: Quantidade de Alunos Evadidos por Classe EconÃ´mica
plt.figure(8, figsize=(7,5))
colors = ['red', 'orange', 'green']
bars = plt.bar(df_contagem['classe_economica'], df_contagem['quantidade_evadidos'], color=colors)

for bar in bars:
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, height + 0.5, str(int(height)), ha='center')

plt.title('Quantidade de Alunos Evadidos por Classe EconÃ´mica')
plt.xlabel('Classe EconÃ´mica')
plt.ylabel('Quantidade')
plt.grid(axis='y', linestyle='--', alpha=0.5)
plt.tight_layout()

# GrÃ¡fico 9: Top 5 Estados Civis com Mais EvasÃ£o
# Garantir que nÃ£o hÃ¡ nulos
df_estado = df.dropna(subset=['estado_civil', 'risco_evasao'])

# Contar evasÃµes por estado civil
evasao_estado = df_estado[df_estado['risco_evasao'] == 1]['estado_civil'].value_counts().nlargest(6)

plt.figure(9, figsize=(8,5))
bars = plt.bar(evasao_estado.index, evasao_estado.values, color='cornflowerblue', edgecolor='black')

# Adicionar rÃ³tulos nas barras
for bar in bars:
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, height + 0.5, str(int(height)), ha='center')

plt.title('Top 5 Estados Civis com Mais Alunos Evadidos')
plt.xlabel('Estado Civil')
plt.ylabel('Quantidade de EvasÃµes')
plt.xticks(rotation=45)
plt.grid(axis='y', linestyle='--', alpha=0.5)
plt.tight_layout()

# GrÃ¡fico 10: EvasÃ£o por Bimestre
# Garantir dados vÃ¡lidos
df_bimestre = df.dropna(subset=['bimestre', 'risco_evasao'])

# Contar evasÃµes por bimestre
evasao_bimestre = df_bimestre[df_bimestre['risco_evasao'] == 1]['bimestre'].value_counts().sort_index()

plt.figure(10, figsize=(8,5))
bars = plt.bar(evasao_bimestre.index.astype(str), evasao_bimestre.values, color='tomato', edgecolor='black')

# RÃ³tulos nas barras
for bar in bars:
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, height + 0.5, str(int(height)), ha='center')

plt.title('Quantidade de Alunos Evadidos por Bimestre')
plt.xlabel('Bimestre')
plt.ylabel('Quantidade de EvasÃµes')
plt.grid(axis='y', linestyle='--', alpha=0.5)
plt.tight_layout()

# GrÃ¡fico 11: EvasÃ£o por Semestre
# Garantir dados vÃ¡lidos
df_semestre = df.dropna(subset=['semestre', 'risco_evasao'])

# Contar evasÃµes por semestre
evasao_semestre = df_semestre[df_semestre['risco_evasao'] == 1]['semestre'].value_counts().sort_index()

plt.figure(11, figsize=(9,5))
bars = plt.bar(evasao_semestre.index.astype(str), evasao_semestre.values, color='darkorange', edgecolor='black')

# Adicionar rÃ³tulos nas barras
for bar in bars:
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, height + 0.5, str(int(height)), ha='center')

plt.title('Quantidade de Alunos Evadidos por Semestre')
plt.xlabel('Semestre')
plt.ylabel('Quantidade de EvasÃµes')
plt.grid(axis='y', linestyle='--', alpha=0.5)
plt.xticks(rotation=45)
plt.tight_layout()

# GrÃ¡fico 12: Quantidade de Alunos Evadidos por NÃºmero de Faltas
plt.figure(12, figsize=(8,5))   
plt.bar(df_faltas_count['faltas_1'], df_faltas_count['quantidade_evadidos'], color='purple')
plt.title('Quantidade de Alunos Evadidos por NÃºmero de Faltas')
plt.xlabel('NÃºmero de Faltas')
plt.ylabel('Quantidade de Alunos Evadidos')
plt.xticks(rotation=45)
plt.grid(axis='y', linestyle='--', alpha=0.5)
plt.tight_layout()

# GrÃ¡fico 13: DistribuiÃ§Ã£o de EvasÃ£o por Semestre
plt.figure(13, figsize=(10,6))
plt.bar(dados_plot['semestre'], dados_plot['total_evasoes'], color='blue', label='Total de EvasÃµes')
plt.bar(dados_plot['semestre'], dados_plot['percentual_evasao'], color='orange', label='Percentual de EvasÃ£o (%)')
plt.title('DistribuiÃ§Ã£o de EvasÃ£o por Semestre')
plt.xlabel('Semestre')
plt.ylabel('Contagem/Percentual')
plt.legend()
plt.grid(axis='y', linestyle='--', alpha=0.5)
plt.tight_layout()

# Certifique-se que df_motivos foi criado antes
if 'df_motivos' not in locals():
    df_model['motivo_evasao'] = df_model.apply(definir_motivo, axis=1)
    df_motivos = df_model.groupby(['risco_predito', 'motivo_evasao']).size().reset_index(name='quantidade')

# GrÃ¡fico 14: Top 5 cursos com mais evasÃ£o
# Garantir que a coluna 'risco_evasao' e 'curso' estÃ£o presentes e vÃ¡lidas
df_evasao_curso = df.copy()
df_evasao_curso = df_evasao_curso.dropna(subset=['risco_evasao', 'curso'])

# Filtrar apenas os alunos que evadiram (risco_evasao == 1)
df_evadidos = df_evasao_curso[df_evasao_curso['risco_evasao'] == 1]

# Contar evasÃµes por curso e selecionar os 5 mais
top_cursos = df_evadidos['curso'].value_counts().nlargest(5)

# Plotar o grÃ¡fico
plt.figure(14, figsize=(8, 5))
bars = plt.bar(top_cursos.index, top_cursos.values, color='steelblue', edgecolor='black')

# Adicionar rÃ³tulos de valor nas barras
for bar in bars:
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, height + 0.5, str(int(height)), ha='center')

plt.title('Top 5 Cursos com Mais Alunos Evadidos')
plt.xlabel('Curso')
plt.ylabel('Quantidade de EvasÃµes')
plt.xticks(rotation=45)
plt.grid(axis='y', linestyle='--', alpha=0.6)
plt.tight_layout()

plt.show()
#FIM DE CODIGO 
# ... inÃ­cio do arquivo ...
import matplotlib
matplotlib.use('Agg')  # <- Adicione esta linha logo apÃ³s os imports do matplotlib
import matplotlib.pyplot as plt
# ... resto dos imports ...

# ... seu cÃ³digo ...

# Exemplo de alteraÃ§Ã£o para salvar grÃ¡ficos:
plt.figure(1, figsize=(12,6))
plt.title("Matriz de ConfusÃ£o - Modelo com 5 Aulas")
plt.savefig('/opt/spark/scripts/grafico1_matriz_confusao.png')
plt.close()

plt.figure(2, figsize=(10, 5))
# ... plot ...
plt.savefig('/opt/spark/scripts/grafico2_distribuicao_real_vs_predito.png')
plt.close()

# Repita para todos os grÃ¡ficos:
# plt.savefig('/opt/spark/scripts/graficoX_nome.png')
# plt.close()

# Exemplo para o trecho que vocÃª enviou:
plt.figure(8, figsize=(7,5))
colors = ['red', 'orange', 'green']
bars = plt.bar(df_contagem['classe_economica'], df_contagem['quantidade_evadidos'], color=colors)
for bar in bars:
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, height + 0.5, str(int(height)), ha='center')
plt.title('Quantidade de Alunos Evadidos por Classe EconÃ´mica')
plt.xlabel('Classe EconÃ´mica')
plt.ylabel('Quantidade')
plt.grid(axis='y', linestyle='--', alpha=0.5)
plt.tight_layout()
plt.savefig('/opt/spark/scripts/grafico8_evadidos_classe_economica.png')
plt.close()

# ... repita para os demais grÃ¡ficos ...

# No final do script, NÃƒO use plt.show() (ou deixe, mas nÃ£o farÃ¡ efeito em ambiente headless)# ... inÃ­cio do arquivo ...
import matplotlib
matplotlib.use('Agg')  # <- Adicione esta linha logo apÃ³s os imports do matplotlib
import matplotlib.pyplot as plt
# ... resto dos imports ...

# ... seu cÃ³digo ...

# Exemplo de alteraÃ§Ã£o para salvar grÃ¡ficos:
plt.figure(1, figsize=(12,6))
plt.title("Matriz de ConfusÃ£o - Modelo com 5 Aulas")
plt.savefig('/opt/spark/scripts/grafico1_matriz_confusao.png')
plt.close()

plt.figure(2, figsize=(10, 5))
# ... plot ...
plt.savefig('/opt/spark/scripts/grafico2_distribuicao_real_vs_predito.png')
plt.close()

# Repita para todos os grÃ¡ficos:
# plt.savefig('/opt/spark/scripts/graficoX_nome.png')
# plt.close()

# Exemplo para o trecho que vocÃª enviou:
plt.figure(8, figsize=(7,5))
colors = ['red', 'orange', 'green']
bars = plt.bar(df_contagem['classe_economica'], df_contagem['quantidade_evadidos'], color=colors)
for bar in bars:
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, height + 0.5, str(int(height)), ha='center')
plt.title('Quantidade de Alunos Evadidos por Classe EconÃ´mica')
plt.xlabel('Classe EconÃ´mica')
plt.ylabel('Quantidade')
plt.grid(axis='y', linestyle='--', alpha=0.5)
plt.tight_layout()
plt.savefig('/opt/spark/scripts/grafico8_evadidos_classe_economica.png')
plt.close()

# ... repita para os demais grÃ¡ficos ...

# No final do script, NÃƒO use plt.show() (ou deixe, mas nÃ£o farÃ¡ efeito em ambiente headless)# ... inÃ­cio do arquivo ...
import matplotlib
matplotlib.use('Agg')  # <- Adicione esta linha logo apÃ³s os imports do matplotlib
import matplotlib.pyplot as plt
# ... resto dos imports ...

# ... seu cÃ³digo ...

# Exemplo de alteraÃ§Ã£o para salvar grÃ¡ficos:
plt.figure(1, figsize=(12,6))
plt.title("Matriz de ConfusÃ£o - Modelo com 5 Aulas")
plt.savefig('/opt/spark/scripts/grafico1_matriz_confusao.png')
plt.close()

plt.figure(2, figsize=(10, 5))
# ... plot ...
plt.savefig('/opt/spark/scripts/grafico2_distribuicao_real_vs_predito.png')
plt.close()

# Repita para todos os grÃ¡ficos:
# plt.savefig('/opt/spark/scripts/graficoX_nome.png')
# plt.close()

# Exemplo para o trecho que vocÃª enviou:
plt.figure(8, figsize=(7,5))
colors = ['red', 'orange', 'green']
bars = plt.bar(df_contagem['classe_economica'], df_contagem['quantidade_evadidos'], color=colors)
for bar in bars:
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, height + 0.5, str(int(height)), ha='center')
plt.title('Quantidade de Alunos Evadidos por Classe EconÃ´mica')
plt.xlabel('Classe EconÃ´mica')
plt.ylabel('Quantidade')
plt.grid(axis='y', linestyle='--', alpha=0.5)
plt.tight_layout()
plt.savefig('/opt/spark/scripts/grafico8_evadidos_classe_economica.png')
plt.close()

# ... repita para os demais grÃ¡ficos ...

# No final do script, NÃƒO use plt.show() (ou deixe, mas nÃ£o farÃ¡ efeito em ambiente headless)